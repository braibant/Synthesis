\documentclass{llncs}

\usepackage{macros}
\usepackage{lstcoq}
\usepackage{lstocaml}
\usepackage{mathpartir}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{stmaryrd}
\usepackage{graphics}
\bibliographystyle{plain}
\pagestyle{plain}


% \authorinfo{Thomas Braibant}
%            {Inria}
%            {thomas.braibant@inria.fr}
% \authorinfo{Adam Chlipala}
%            {MIT}
%            {adamc@csail.mit.edu}
\author{Anonymous}
\institute{}
\title{Formal verification of hardware synthesis}
\newcommand{\project}{Fe-Si}
\newcommand{\action}{action}
\newcommand{\denote}[1]{\llbracket #1 \rrbracket}
\newcommand{\denotety}[1]{\denote{\mathtt{#1}}_{\mathtt{ty}}}
\newcommand{\denotemem}[1]{\denote{\mathtt{#1}}_{\mathtt{mem}}}

\begin{document}
\maketitle

\begin{abstract}
  We report on the implementation of a certified compiler for an
  high-level hardware description language (HDL) called \emph{Fe-Si}
  (FEatherweight SynthesIs).
  %
  Fe-Si is a simplified version of Bluespec, an HDL based on a notion
  of \emph{guarded atomic actions}. Fe-Si is defined as a
  dependently typed deep-embedding in Coq. The target language of the
  compiler corresponds to a synthesisable subset of Verilog or VHDL.
  %
  One key of our approach is that input programs to the compiler can
  be defined and proved correct inside Coq. Then, we use extraction
  and a Verilog back-end (written in OCaml) to get a certified version
  of some hardware designs.
\end{abstract}

\section*{Introduction}
Verification of hardware designs has been thoroughly investigated, and
yet, obtaining provably correct hardware of significant complexity is
usually considered challenging and time-consuming. 
%
On the one hand, a common practice in hardware verification is to take
a given design written in an hardware description language like
Verilog or VHDL, and argue about this design in a formal way using a
model checker or an SMT solver.
%
On the second hand, a completely different approach is to design
hardware via a shallow-embedding of circuits in a theorem
prover~\cite{hanna-veritas,UCAM-CL-TR-77,hunt89,vamp,certifying-circuits-in-type-theory}.
%
Yet, both kind of approach suffer from the fact that most hardware
designs are expressed in low-level register transfer languages (RTL)
like Verilog or VHDL, and that the level of abstraction they provide
may be too low to do short and meaningful proof of high-level
properties.

\medskip

To raise this level of abstraction, industry moved to \emph{hardware
  synthesis} using higher-level languages, e.g., System-C,
Esterel~\cite{DBLP:conf/birthday/Berry00} or
Bluespec~\cite{bluespec}, in which a high-level source program is
compiled to an RTL description. 
%
High-level synthesis has two benefits. 
%
First, it reduces the effort necessary to produce an hardware design.
%
Second, writing or reasoning about a high-level program is simpler
than reasoning about the (much more complicated) RTL description
generated by a compiler.
%
However, the downside of high-level synthesis is that there is no
formal guarantee that the generated circuit description behaves
exactly as prescribed by the semantics of the source
program, making verification on the high-level program useless in the
presence of compiler-introduced bugs.
%

\medskip In this paper, we investigate the formal verification of a
lightly optimizing compiler from a Bluespec-inspired language called
\project{} to RTL, quite literally applying the ideas behind the
CompCert project~\cite{Leroy-Compcert-CACM} to hardware synthesis.

\medskip

\project{} can be seen as a stripped-down and simplified version
of Bluespec: in both languages, hardware designs are described in
terms of \emph{guarded atomic actions} on storage elements. 
%
In our development, we define a (dependently-typed) deep-embedding of
the \project{} programming language in Coq using \emph{parametric
  higher-order abstract syntax (PHOAS)}~\cite{phoas-chlipala}, and
give it a semantics\thomas{~} using an interpreter: the semantics of a program
is a Coq function that takes as inputs the current state of the
storage elements, and produces a list of updates to be commited to
storage elements.
%
The one odditiy here is that this language and its semantics have a
flavour of \emph{transactional memory}, where updates to state
elements are not visible before the end of the transaction (a
time-step).
%
Our target language can be sensibly interpreted as \emph{clocked
  sequential machines}: we generate an RTL description syntactically
described as combinational definitions and next-state assignements.

\medskip

What is new about \project{} is that we embed a hardware decription
language as a domain-specific-language in Coq: circuits correspond to
a given datastructure implemented in Coq.
%
In particular, this makes it possible to use Coq as a metaprogramming
tool to describe circuits: as an example, we shall see how we can
build succint, and provably correct, description of recursive
circuits.



\subsubsection{Contributions.}
We summarize the contributions of this work as follows:
\begin{itemize}
\item we demonstrate a novel use of PHOAS as a way to embed domain
  specific languages (DSLs) in the Coq proof assistant;
\item we define such a DSL for a (minimal, high-level) hardware
  description language;
\item we prove the correctness of a compiler for this DSL that
  produces RTL code; 
\item we implement several circuits in this DSL, and argue about their
  correctness. 
\end{itemize}

\section{Overview of Fe-Si}
Fe-Si is a purely functional language built around a \emph{monad} that
makes it possible to define circuits. We start with a customary
example: we show the implementation of a half adder.
\begin{coq}
Definition hadd (a b: Var Bool) : action [] (Bool $\otimes$ Bool) :=
$\quad$do carry <- ret (andb a b; 
$\quad$do sum    <- ret (xorb a b);
$\quad$ret (carry, sum).  
\end{coq}
The typing of this circuit show that it has two input wires, and
return a tuple of values. 
%
Here, we use Coq notations to implement some syntactic sugar: we
borrow the \texttt{do}-notation to denote the monadic bind, and use
\coqe{ret} as a short-hand for return. 
% 
Our explicit use of return may seem odd. It is due to the fact that
Fe-Si has two classes of syntactic values, expressions and actions,
and that return takes as argument an
expression\footnote{Unfortunately, it is not possible to define return
  as an implicit coercion from expressions to actions in our setting.}. 

Up to this point, Fe-Si can be seen as an extension of the Lava
language, implemented in Coq rather than Haskell. Yet, using Coq as a
metalanguage offers the possibility to use dependent types in our
circuit descriptions. For instance, one can define an adder circuit of
the following type:
\begin{coq}
Definition adder n (a b: Var (Int n)): action [] (Int n) := ...
\end{coq}
In this definition, \coqe{n} of type \coqe{nat} is a formal parameter
that denotes the size of the operands and the size of the result as
well. \thomas{(Here, we neglect the overflow that may occur when computing the
result.)}

\subsubsection{Stateful programs.}
Fe-Si also features a small set of primitives for interacting with
\emph{memory elements} that hold mutable state. In the following
snippet, we build a counter that increments its value when its input
is true.
\begin{coq}
Definition $\Phi$ := [Reg (Int n)]
Definition count n (tick: Var Bool) : action $\Phi$ (Int n) :=
$\quad$do x <- !member_0;
$\quad$do _ <- if tick then {member_0 ::= x + 1} else {ret tt}; 
$\quad$ret x. 
\end{coq}
Here, $\Phi$ is an environment that defines the set of memory elements
(in a broad sense) of the circuit. In the first line, we read the
content of the register at position \coqe{member_0} in $\Phi$, and
bind this value to \coqe{x}. Then, we test the value of the input
\coqe{tick}, and when it is true, we increment the value of the
register. In any case, the output is the old value of the counter.

The above ``if-then-else'' construct is defined using two primitives
for guarded atomic actions that are reminiscent of transactionnal
memory monads: \coqe{assert} and \coqe{orElse}. The former aborts the
current action if its argument is false.
%
The latter takes two arguments $a$ and $b$, and first executes $a$; if
it aborts, then the effects of $a$ are discarded and $b$ is run. If
$b$ aborts too, the whole action \coqe{$a$ orElse $b$} aborts.

\subsubsection{Synchronous semantics.} Recall that Fe-Si programs are
intended to describe hardware circuits. Hence, we must stress that
they are interpreted in a synchronous setting.
%
From a logical point of view the execution of a program (an atomic
action) is clocked, and at each tick of its clock, the computation of
its effects (i.e., updates to memory elements) is instantaneous; 
yet these effects are applied all at once between ticks. 
%
In particular this means that it is not possible to observe, e.g.,
partial updates to the memory elements, nor transient values in
memory.

\subsubsection{From programs to circuits.} At this point, the reader may
wonder how it is possible to generate circuits in a palatable format
out of Fe-Si programs. Indeed, using Coq as a meta-language to embed
Fe-Si yields two kind of issues. First, Coq lacks any kind of I/O; and
second, a Fe-Si program may have been built using arbitrary Coq code,
including, e.g., higher-order functions or fixpoints.

Fortunately, Coq's extraction mechanism makes it possible to solve
both problems at once: it generate OCaml code from Coq
programs. Starting from a closed Fe-Si program \coqe{foo}, we put the
following definition in given Coq file: 
\begin{coq}
Definition bar := fesic foo.  
\end{coq}
The extracted OCaml term that corresponds to \coqe{bar} evaluates (in OCaml) to a
ground RTL circuit. Then, we can use an (unverified) back-end that
pretty-prints this RTL code as regular Verilog code. 
%
(We reckon that this is some devious use of the extraction mechanism,
that palliates the fact that there is currently no I/O mechanism in
Coq.)

\section{From Fe-Si to RTL}

In this section, we shall present our source (Fe-Si) and target (RTL)
languages, along with their semantics. For the sake of space, we leave
the full description of this compilation process out of the scope of
this paper.

\subsection{The memory model}
Fe-Si programs are meant to describe sequential circuits, whose
``memory footprint'' must be known statically. We take a declarative
approach: each state-holding element that is used in a program must be
declared. 
%
We currently have three types of memory elements: inputs, registers,
and register files. A register hold one value of a given type, while a
register file of size $n$ stores $2^n$ values of a given type. 
%
An input is a memory element that can only be read by the circuit,
and whose value is driven by the external world.
%
We show the inductive definitions of types and memory elements in
Fig.~\ref{fig:type}. 
%
We have four constructors for the type \coqe{ty} of types: \coqe{Unit}
(the unit type), \coqe{B} (Booleans), \coqe{Int} (integers of a given
size), and \coqe{Tuple} (tuples of types). The inductive definition of
memory elements (\coqe{mem}) should be self-explaining. 

We endow these inductive definitions with a denotational semantics: we
implement Coq functions that map such reified types to the obvious Coq
types they denote.

\begin{figure}
  \centering
\begin{threelistings}
\begin{coq}
Inductive ty : Type :=
| Unit : ty 
| B : ty 
| Int : nat -> ty
| Tuple : list ty -> ty.     
\end{coq}&
\begin{coq}
Inductive mem : Type :=
| Input: ty ->  mem
| Reg : ty -> mem
| Regfile : nat -> ty -> mem. 
$ $
\end{coq}
&
\begin{coq}
Fixpoint $\denotety{.}$ : ty -> Type := ...
Fixpoint $\denotemem{.}$ : mem -> Type := ...
Fixpoint $\denote{.}$ : list mem -> Type := ...

$ $
\end{coq}
\end{threelistings}
\caption{Types and memory elements}
  \label{fig:type}
\end{figure}




\subsection{Fe-Si}
The definition of Fe-Si programs (\coqe{action} in the following)
takes the PHOAS approach. 
%
That is, we define an inductive type family parametrized by an
arbitrary type \coqe{V} of variables, where binders bind variables
instead of arbitrary terms (as it would be the case using HOAS), and
those variables are used explicitly via a dedicated term constructor.
%
The definition of Fe-Si syntax is split in two syntactic classes:
expressions and actions. 
%
Expressions are side-effects free, and are built from variables,
constants, and operations.
%
Actions are made of control-flow structures (assertions and
alternatives), binders, and memory operations. 

In this work, we follow an intrinsic
approach~\cite{DBLP:journals/jar/BentonHKM12}: we mix the definition
of the abstract syntax and the typing-rules from the start. That is,
the type system of the meta-language (Coq) enforces that all Fe-Si
programs are well-typed by construction.
%
Besides the obvious type-oblivious definitions (e.g., it is not
possible to add a Boolean and an integer), this means that the
definition of operations on state-holding elements requires some care.
%
Here, we use dependently-typed de Bruijn indices. 
\begin{coq}
Inductive member : list mem -> mem ->  Type :=
| member_0 : forall E t, member (t::E) t
| member_S : forall E t x, member E t -> member (x::E) t.
\end{coq}
Using the above definition, a term of type \coqe{member $\Phi$ M} denotes
the fact that the memory element \coqe{M} appears at a given position
in the environment of memory elements $\Phi$. 
%
We are now ready to present the (elided) Coq definitions of the
inductives for \coqe{expr} and \coqe{action} in Fig.~\ref{fig:fesi}.
%
(For the sake of brevity, we omit the constructors for accesses to
register files, in the syntax and, later, in the semantics. We refer
the reader to the supplementary materials for more details.)
%
Our final definition \coqe{Action} of actions is a polymorphic
function from a choice of variables to an action.

\begin{figure}
  \centering
\begin{coq}
Section t. 
Variable V: ty -> Type. Variable $\Phi$: list mem. 
Inductive expr: ty -> Type :=
| Evar : forall t (v : V t), expr t
(* operations on Booleans *)
| Eandb : expr B -> expr B -> expr B | ... 
(* operations on words *)
| Eadd : forall n, expr (Int n) -> expr (Int n) -> expr (Int n) | ... 
(* operations on tuples *)
| Efst : forall l t, expr (Tuple (t::l)) -> expr t | ...

Inductive action: ty -> Type:=
| Return: forall t, expr t -> action t
| Bind: forall t u,  action  t -> (V t -> action u) -> action u
(* control-flow *)
| OrElse: forall t, action t -> action t -> action t.
| Assert: expr B -> action Unit    
(* memory operations on registers *)
| RegRead : forall t, member $\Phi$ (Reg t) -> action t
| RegWrite: forall t, member $\Phi$ (Reg t) -> expr t -> action Unit
(* memory operations on register files, and inputs *)
| ... 
End t. 
Definition Action $\Phi$ t := forall V, action V $\Phi$ t.  
\end{coq}
  \caption{The syntax of expressions and actions}
  \label{fig:fesi}
\end{figure}

\subsubsection{Semantics.}
We endow Fe-Si programs with a simple synchronous semantics:  starting
from an initial state, the execution of a Fe-Si programs corresponds
to a sequence of atomic updates to the memory elements. 
%
Each step goes as follows: reading the state, computing an update to
the state, commiting this update.
%

\begin{figure*}
  \centering
  \begin{mathpar}
    \inferrule{\Gamma \vdash e \leadsto v} {\Gamma, \Delta \vdash
      \mathtt{Return}~e \to \mathtt{Some} (v,\Delta)}
    \\
    % bind
    \inferrule{ \Gamma, \Delta_1 \vdash a \to \mathtt{None} } {\Gamma,
      \Delta_1 \vdash \mathtt{Bind}~a~f \to \mathtt{None}} \and
    \inferrule{ \Gamma, \Delta_1 \vdash a \to \mathtt{Some}~(v,
      \Delta_2) \and \Gamma, \Delta_2 \vdash f~v \to r} {\Gamma,
      \Delta_1 \vdash \mathtt{Bind}~a~f \to r}
    \\
    % assert
    \inferrule{\Gamma \vdash e \leadsto \mathtt{true}} {\Gamma, \Delta
      \vdash \mathtt{Assert}~e \to \mathtt{Some} (\mathtt{tt},\Delta)}
    \and \inferrule{\Gamma \vdash e \leadsto \mathtt{false}} {\Gamma,
      \Delta \vdash \mathtt{Assert}~e \to \mathtt{None}}
    \\
    % register
    \inferrule{\Gamma(r) = v} {\Gamma, \Delta \vdash
      \mathtt{RegRead}~r \to \mathtt{Some} (r,\Delta)} \and
    \inferrule{\Gamma \vdash e \leadsto v} {\Gamma, \Delta \vdash
      \mathtt{RegWrite}~r~e \to \mathtt{Some}
      (\mathtt{tt},\Delta\oplus(r,v))}
        
  \end{mathpar}
\caption{Dynamic semantics of Fe-Si programs}\label{fig:fesi-sem}
\end{figure*}

The reduction rules of Fe-Si programs are defined in
Fig.~\ref{fig:fesi-sem}. The judgement $\Gamma, \Delta \vdash a \to r$
reads ``in the state $\Gamma$ and with the partial update $\Delta$,
evaluating $a$ produces the result $r$'', where $r$ is either
\coqe{None} (meaning that the action aborted), or %
\coqe{Some (v, $\Delta$)} (meaning that the action returned the value
\coqe{v} and the partial update $\Delta$). 
%
The rules for the reduction of \coqe{Bind} may seem odd, in that they
do not modify the state $\Gamma$.
%
This is because the PHOAS approach makes it possible to manipulate
closed-terms: we hijack Coq's $\beta$-reduction when dealing with
$f~v$, and we do not need to have an explicit treatment of the binders
nor the reduction environments.

There are two peculiarities here: first, following the definition of
$\oplus$, if two values are written to a memory element, only the
first one (in program order) is commited; second, reading a register
yield the value that was held at the beginning of the time step. 
%
(While it may seem an odd choice for a general purpose programming
language, it is meaningful when it comes to hardware. We come back to
this point in \S\ref{sec:discussion}.)

Finally, we define a wrapper function that computes the next state of
the memory elements, using the aforementioned evaluation relation
(starting with an empty partial update). 
\begin{coq}
Definition Next {t} $\Phi$ (st: $\denote{\Phi}$) (A : Action Phi t) : $\denote{\Phi}$ := ...
\end{coq}

\subsection{RTL} 
We now turn to the presentation of our target language, which sits at
the register-transfer level. At this level, synchronous circuit can be
faithfully described as a set of state holding elements, and a
next-state function, implemented using combinational
logic~\cite{DBLP:journals/cj/Gordon02}.
%
Therefore, The definition of RTL programs (\coqe{block} in the
following) is quite simple: a program is simply a telescope of
expressions (combinational operations, or reads from state holding
elements), with a list of effects (i.e, writes to state holding
elements) at the end. 

We show the definition of expressions, telescopes, and blocks in
Fig.~\ref{fig:rtl}. 
%
The definition of expressions is similar to the one we used for Fe-Si,
excepts that we have constructors for reads from memory elements, and
that we moved to ``three-adress code''.
%
(That is, operands are variables, rather than arbitrary expressions.)
%
A telescope (type \coqe{scope A}) can be thought of as a sequence of
bindings of expressions, with an element of type \coqe{A} at the
end (\coqe{A} is instantiated later with a list of effects.)
%
Intuitively, the first binding of a telescope can only read from
memory elements; the second binding may use the first value, or read
from memory elements; and so on and so forth.

A \coqe{block} is a telescope, with three elements at the end: a
guard, a return-value, and a (dependently-typed) list of effects. 
%
The value of the guard (a Boolean) is equal to true when the
return-value and the effects are valid (i.e., the effects should be
commited to memory); and false otherwise.
%
The return-value denotes the outputs of the circuits. 
%
The datatype \coqe{effects} encode, for each memory element of the
list $\Phi$, either an effect (a write of the right type), or None
(meaning that this memory element is never written to). (For the sake
of brevity, we omit the particular definition of dependently-typed
heterogeneous lists \coqe{DList.T} that we use here.)


\begin{figure}
  \centering
\begin{coq}
Section t. 
Variable V: ty -> Type. Variable $\Phi$: list mem. 
Inductive expr: ty -> Type :=
| Evar : forall t (v : V t), expr t
(* read from memory elements *)
| Einput : forall t, member $\Phi$ (Input t) -> expr t
| Eread_r : forall t, member $\Phi$ (Reg t) -> expr t
| Eread_rf : forall n t, member $\Phi$ (Regfile n t) -> V (Int n) -> expr t
(* operations on Booleans *)
| Emux : forall t, V B -> V t -> V t -> expr t
| Eandb : V B -> V B -> V B | ... 
(* operations on words *)
| Eadd : forall n, V (Int n) -> V (Int n) -> expr (Int n) | ... 
(* operations on tuples *)
| Efst : forall l t, V (Tuple (t::l)) -> expr t | ...

Inductive scope (A : Type): Type :=
| Send : A -> scope A
| Sbind : forall (t: ty), expr t -> (V t -> scope A) -> scope A. 

Inductive write : mem -> Type :=
| WR : forall t, V t -> V Tbool -> write (Reg t)
| WRF : forall n t, V t -> V (Int n) -> V B ->  write (Regfile n t). 
     
Definition effects := DList.T (option $\circ$ write) $\Phi$. 
Definition block t := scope (V B * V t *  effects).         
End t.
Definition Block $\Phi$ t := forall V, block $\Phi$ V t.
\end{coq}
  \caption{RTL programs with three-adress code expressions}
  \label{fig:rtl}
\end{figure}

\subsubsection{Semantics.} We now turn to define the semantics of our RTL
language. 
%
To define  evaluation 
We first define a denotation for closed expressions (in the
same way as we did at the source-level, except that it is not a
recursive definition).
\begin{coq}
Variable $\Gamma$: $\denote{\Phi}$. 
Definition eval_expr (t : ty) (e : expr $\denotety{.}$ t) : $\denotety{.}$:=
match e with
| Evar t v => v
| Einput t v => DList.get v $\Gamma$
| Eread  t v =>  DList.get v $\Gamma$
| Eread_rf n t v adr => Regfile.get (DList.get v $\Gamma$) adr
| Emux t b x y => if b then x else y 
| Eandb a b => andb a b | ...
| Eadd n a b => Word.add a b  | ...
| Efst l t e => Tuple.fst e | ...
end. 
\end{coq}

We now turn to define the (simple) denotation of telescopes: it is a
simple recursive function that evaluates bindings in order, and apply
an arbitrary function on the final (closed) object. 
\begin{coq}
Fixpoint eval_scope {A B} (F : A -> B) (T : scope $\denotety{.}$ A) :=
match T with 
| Send X => F X
| Sbind t e cont => eval_scope F (cont (eval_expr t e))
end.   
\end{coq}
%
The final piece that we need is the denotation that corresponds to the
\coqe{write} type. This function takes as argument a single effect,
the initial state of this memory location, and either returns a new
state for this memory location, or returns \coqe{None}, meaning that
location is left in its previous state.
\begin{coq}
Definition eval_effect (m : mem) : 
$\qquad$option (write $\denotety{.}$ m) -> $\denotemem{m}$ -> (option $\denotemem{m}$) := ... 
\end{coq}
%
Using all this pieces, it is quite easy to define what is the final
next-state function. 
\begin{coq}
Definition Next {t} $\Phi$ ($\Gamma$: $\denote{\Phi}$) (B : Block $\Phi$ t) : $\denote{\Phi}$ := ...
\end{coq}

\subsection{Compiling Fe-Si to RTL} 
Our syntactic translation from Fe-Si to RTL is driven by the fact that
our RTL language does not allow clashing assignements: syntactically,
each register and register-file is updated at most one \coqe{write}
expression.
%
With a wrinkle, we could say that we move to a language with
\emph{single-static assignements}. 

\subsubsection{From control-flow to data-flow.}To do so, we have to transform
the control-flow (the \coqe{Assert} and \coqe{OrElse}) of Fe-Si
programs into data-flow.
%
We can do that in hardware, because circuits are inherently parallel:
for instance, the circuit that compute the result of the conditional
expression \mbox{\coqe{e ? a : b}} is a circuit that computes the value of
\coqe{a} and the value of \coqe{b} in parallel, and then uses the
value of \coqe{e} to select the right value for the whole expression. 

\subsubsection{Administrative normal form.} Our first compilation pass
transforms Fe-Si programs into an intermediate language that
implements A-normal form. That is, we assign names to every
intermediate computation.
%
In order to do so, we also have to resolve the control-flow. To be
more specific, given an expression like
\begin{coq}
do x <- (A OrElse B); ... 
\end{coq}
we want to know statically to what value \coqe{x} needs to be bound
and when this value is \emph{valid}. 
%
In this particular case, we remark that if \coqe{A} yields a value
$v_A$ which is valid, then \coqe{x} needs to be bound to $v_A$; if
\coqe{A} yields a value that is invalid, then \coqe{x} needs to be
bound to the value returned by \coqe{B}. In any case, the value bound
in \coqe{x} is valid whenever the value returned by \coqe{A} or the
value returned by \coqe{B} is valid.

More generally, our compilation function takes as argument an
arbitrary function, and returns a telescope that binds three values:
(1) a \emph{guard}, that denotes the validity of the following
components of the tuple; %
(2) a \emph{value}, that is bound by the telescope to denote the value
that was returned by the action; %
(3) a list of \emph{nested effects}, which are a lax version of the
effects that exist at the \coqe{RTL} level.

The rationale behind these nested effects is to represent trees of
conditional blocks, with writes to state-holding elements at the
leaves. (Using this data-type, several paths in such a tree may lead
to a write to a given memory location; in this case, we use a notion
of program order to discriminate between clashing assignements.)

\subsubsection{Linearizing the effects} Our second compilation pass
flattens the nested effects that were introduced in the first pass.

The idea of this translation is to associate two values to each
register: a \emph{data} value (the value that ought to be written) and
a \emph{write-enable} value. The data value is commited (i.e., stored)
to the register if the write-enable Boolean is true.
%
Similarly, we associate three values to each register-file: a data, an
address, and a write-enable. The data is stored to the field of the
register file selected by the address if the write-enable is true.  

The heart of this translation is a \coqe{merge} function that takes
two \coqe{write} of the same type, and returns a telescope that
encapsulates a single \coqe{write}: 
\begin{coq}
Definition merge s (a b : write s): scope (option (write s)) := ...   
\end{coq}
Despite requiring a bit of dependent-types hackery\footnote{The
  reader may wonder why we need an option here; the answer is that we
  could do without it, at the price of a more complicated definition
  for \coqe{merge} that uses the fact that the type
%
  \mbox{\coqe{write (Input t)}} is not inhabited.}, the definition of
\coqe{merge} is the expected one.
%
For instance, in the register case, given $(v_a,we_a)$ (resp. $(v_b,
we_b)$) the value and the write-enable that corresponds to \coqe{a},
the write-enable that corresponds to the merge of \coqe{a} and
\coqe{b} is $we_a || we_b$, and the associated data is \mbox{$we_a~?~v_a :
v_b$}.

\subsubsection{Moving to RTL.} The third pass of our compiler translates
the previous intermediate language to RTL, which amounts to a simple
transformation into three-address code. This transformation simply
introduce new variables for all the intermediate expressions that
appear in the computations. 

\subsection{Lightweight optimizations}
We will now describe two optimizations that we perform on programs
expressed in the RTL language. 
%
The first one is syntactic version of common sub-expression
elimination, intended to reduce the amount of bindings, and introduce
more sharing. 
%
The second is a semantic common sub-expression elimination that aims
to reduce the size of the Boolean formula that were generated in the
previous translation passes.

\subsubsection{Syntactic common-subexpression elimination.}
We implement CSE with a simple recursive traversal of RTL
programs. Indeed, since there is no iteration involved, there is no
need to perform any kind of data-flow analysis. (Here we follow the
overall approach used by Chlipala~\cite{DBLP:conf/popl/Chlipala10}.)

Contrary to our previous transformations that were just ``pushing
variables around'' for each possible choice of variable representation
\coqe{V}, here we need to tag variables with their symbolic values,
which are approximations the actual values held by variables.
% 
%
Then, CSE goes as follows. We fold through a telescope and maintain a
mapping from symbolic values to variables. For each binder of the
telescope, we compute the symbolic representation of the expression
that is bound. 
%
If this symbolic value is already in the map, we avoid the creation of
an extraneous binder. Otherwise, we do create a new binder, and extend
our association list accordingly. 
 
% Between closure
% conversion and flattening, we perform intrapro- cedural common
% subexpression elimination (CSE) on closed pro- grams. Since our
% languages have no intraprocedural iteration con- structs, there is no
% need to perform dataflow analysis. Instead, a single recursive
% traversal of a program suffices. The optimization still simplifies
% cases like application of a known function, where it is possible to
% avoid building a closure.

% As we descend into a program’s structure, we maintain a map- ping from
% variables to symbolic values, as defined below.  Symbolic values s ::=
% #n | c | () | s, s | inl(s) | inr(s) Values not built from the basic
% constant, unit, product, and sum constructors are represented with
% symbolic variables #n, where a fresh n is generated for each new
% input-program variable that cannot be determined to have more specific
% structure.  The purpose of CSE is to remove some redundant bindings
% and case analyses. This transformation may sound complicated enough to
% require conversion of input programs to first-order form to analyze
% them. However, it is possible to implement CSE in an elegant
% higher-order way. In translating a parametric program P , we must
% produce a CSE’d version of it for each possible variable
% representation var. Our solution is to do so by instantiating P at
% variable type var * sval, where sval is the type of symbolic values s.

% Thus, each variable is tagged with a symbolic representation, and this
% representation may be accessed directly at use sites. The main
% translation maintains a mapping from symbolic values to vari-
% ables. We use this mapping to simplify case expressions with dis-
% criminees that we see statically are either inl or inr. When proceed-
% ing under a let binder, the translation evaluates the bound expres-
% sion symbolically. If the result is in the map, we avoid creating a
% new binder in the translation. Instead, we apply the binder body,
% which is a function over variable/value pairs, to the variable that
% our map associates with the appropriate symbolic value, paired with
% that value. If the value we are binding is not found in the map, we do
% create a new binder, and, in the recursive call inside the binder’s
% scope, we add the new variable to the symbolic map.  The main
% correctness theorem for this translation is proved very similarly to
% the main theorem for CPS conversion. The proof can be a bit simpler
% because we need no value compatibility relation; CSE has no effect on
% the values that appear during program evaluation.  We prove the main
% theorem with about 20 lines of tactic code for performing appropriate
% case analyses, applying IHes and a lemma about primops, and
% materializing known facts about variables men- tioned in expression
% equivalence derivations.

\subsubsection{Using BDDs to reduce boolean expressions.}
Our compilation process introduces a lot of extra boolean
variables. We use BDDs to implement semantic common-subexpression
elimination. The purpose of this pass is to simplify the extraneous
boolean operations that were introduced by our compilation passes. In
order to simplify only the Boolean computations that we introduced, we
could use two different kinds of Booleans (the one that were present
at the source level, and the others); and use our simplification pass
only on the later. 

\textbf{Implementing OBDDs in Coq.} 
Persistence of the data-structure, reasonning about hash-consing.

\subsection{Putting all together}
In the end, we prove that our whole compilate that goes from Fe-Si to
RTL, and implements the two lightweight optimisations described above
is correct. That is, we prove that that next-step functions at the
source level and the target level are compatible.

\section{Design and verification of a sorter core}
We now turn to the description of a first hardware circuit implemented
and proved correct in Fe-Si. 

A \emph{sorting network}~\cite{DBLP:books/mg/CormenLRS01} is a
parallel sorting algorithm that sorts a sequence of values using only
compare-and-swap operations, in a data-independent way. This makes it
suitable for an hardware implementation.

Bitonic sorters for sequences of length $2^n$ can be generated using
short and simple algorithmic descriptions. Yet, formally proving their
correctness is a challenge that was only partially solved in two
different line of previous work.
%
First, sorter core generators were studied from an hardware design
perspective in Lava~\cite{DBLP:conf/charme/ClaessenSS01}, but formal
proof was limited to circuits with a fixed size -- bounded by tge
performances of the automated verification tools that existed at this
time.
%
Second, machine-checked formal proofs of bitonic sort were performed
e.g., in Agda~\cite{DBLP:conf/types/BoveC04}, but without a
connection with an actual hardware implementation. 
%
Our main contribution here is to implement such generators, and to
propose a formal proof of their correctness.

More precisely, we implemented a version of bitonic sort as a regular
Coq program, and proved that it sorts its inputs. This proof follows
closely the one described by Bove and
Coquand~\cite{DBLP:conf/types/BoveC04} -- in Agda -- and amounts to
roughly 1000 lines of Coq, including a proof of the so-called
\mbox{0-1~principle}.

Then, we implemented a version of bitonic sort as a Fe-Si program,
that mimicked the structure of the previous one. We present
side-by-side the Coq implementation of \coqe{reverse} in
Fig.~\ref{fig:reverse}.
%
The version on the left-hand side can be seen as a specification: it
takes as argument a sequence of $2^n$ inputs\footnote{Such a sequence
  is represented as a complete binary tree of depth $n$, with data on
  the leaves.}, and reverse the order of this sequence.
%
The code on the right-hand side implements part of the
connection-pattern of the sorter. More precisely, it takes as input a
sequence of input variables and build a circuit that outputs this
sequence in reverse order. 

Next, we turn to the function that is at the heart of the bitonic
sorting network.
%
A bitonic sequence is a sequence $(x_i)_{0 \le i < n}$ such that
$$ x_0 \le \cdots x_k \ge \cdots x_n, \text{with } 0 \le k < n $$
or a circular shift of such a sequence.
%
Given a bitonic input sequence of length $2^n$, the left-hand side
\coqe{min_max_swap} returns two bitonic sequences of length $2^{n-1}$,
such that all elements in the first sequence are smaller or equal to
the elements in the second sequence. 
%
The right-hand side version of this function builds the corresponding
comparator network: it takes as arguments a sequence of input
variables, and returns a circuit. 

We go on with the same ideas to finish the Fe-Si implementation of
bitonic sort. The rest of the code is unsurprising, except that it
requires to implement a dedicated bind operation of type
\begin{coq}
forall U n : Var (domain n) -> (T n -> action [] Var U) -> action [] Var U. 
\end{coq}
that makes it possible to recover the tree structure out of the
result-type of a circuit (\coqe{domain n}).

\begin{figure}
  \centering
\begin{twolistings}
\begin{coq}
(* Lists of length $2^n$ represented as trees *)
Inductive tree (A: Type): nat -> Type :=
| L : forall x : A, tree A 0
| N : forall n (l r : tree A n), tree A (S n). 
$ $
Definition leaf  {A n} (t: tree A 0) : A := ...
Definition left  {A n} (t: tree A (S n)) : tree A n := ...
Definition right {A n} (t: tree A (S n)) : tree A n := ...

Fixpoint reverse {A} n (t : tree A n) :=
match t with 
| L x => L x
| N n l r => 
  let r := (reverse n r) in 
  let l := (reverse n l) in 
  N n r l
end.

$ $

Variable cmp: A -> A -> A * A.
Fixpoint min_max_swap {A} n : 
  forall (l r : tree A n), tree A n * tree A n :=
match n with 
| 0 => fun l r => 
  let (x,y) := cmp (leaf l) (leaf r) in (L x, L y)
| S p => fun l r => 
  let (a,b) := min_max_swap p (left l) (left r) in 
  let (c,d) := min_max_swap p (right l) (right r) in 
  (N p a c, N p b d)
end. 
\end{coq}
& $\quad$
\begin{coq}
Variable A : ty.        
Fixpoint domain n := match n with 
| 0 => A
| S n => (domain n) $\otimes$ (domain n)
end. 

Notation T n := (tree (Var A) n). 
Notation C n := action nil Var (domain n). 

Fixpoint reverse n (t : T n) : C n  :=
match t with 
| L x => ret (Evar x)
| N n l r => 
  do r <- reverse n r;
  do l <- reverse n l;
  ret [tuple r, l]
end.

Notation mk_N x y := ([tuple x,y]).

Variable cmp : Var A -> Var A -> action nil Var (A $\otimes$ A).
Fixpoint min_max_swap n : 
  forall (l r : T n), C (S n) :=
match n  with 
| 0 => fun l r => 
  cmp (leaf l) (leaf r)
| S p => fun l r => 
  do (a,b) <- min_max_swap p (left l) (left r);
  do (c,d) <- min_max_swap p (right l) (right r); 
  ret ([tuple mk_N a c, mk_N b d])
end.
\end{coq}
\end{twolistings}
  
  \caption{Comparing the specification and the Fe-Si implementation}
  \label{fig:reverse}
\end{figure}

We are now ready to state (and prove) the correctness of our sorter
core. We chose to settle in a context where the type of data that we
sort are integers of a given size, but we could generalize this proof
to other data-types, e.g., to sort tuples in a lexicographic order.
\begin{coq}
Theorem sort_correct : ...  
\end{coq}
\subsubsection{Testing the design}
Finally, we indulge ourselves with the pleasure to test a design that
was formally proven, using a stock Verilog
simulator~\cite{iverilog}. We set the word-size to 4, and the number
of inputs of the sorter to 16, and we generate the corresponding
Verilog code. Unsurprisingly, the sorter core sorts its input
sequence.


\section{Verifying a stack machine.}
The circuit that was described in the previous section is a simple
combinational sorter: we could have gone one step further in this
verification effort and pipelined our design by resgistering the
output of each compare-and-swap operators. However, we chose here to
describe a more interesting design: a hardware implementation of a
simple stack machine, inspired from the IMP virtual machine, i.e., a
small subset of the Java virtual machine.

\section{Further discussion}\label{sec:discussion}

\subsubsection{Testing designs}
In order to gain confidenced in the fact that there is no lapse in
either the semantics of the source language, nor the semantics of the
target language, we test the simulated execution of compiled designs
against our semantics. 

Indeed, our use of program extraction is more delicate than what is
done in, e.g., CompCert, because our program transformations use
dependent types intensively. In the end, either Coq extraction
mechanism or our Verilog back-end could introduce bugs in the
generated code.
%
Moreover, since the long-term idea is to generate high-confidence
hardware, one should not blindly trust formally certified code that
has not been tested: their might always be some lapse in the
specification itself.

\subsubsection{Optimising the layout of the desings}
Lava features a number of layout primitives, that makes it possible to
describe more precisely what should be the hardware layout, yielding
more efficient FPGA implementations. From a verification point of
view, these layout combinators are irrelevant (they should have the
same semantics as a general purpose binding combinator). Yet, we could
investigate the use of a more expressive monad for combinational and
pipelined circuits, in order to produce more efficient implementations. 

\subsubsection{Scheduling actions}
In Bluespec, a program is a set of rules (i.e., guarded atomic
actions) that are non-deterministically executed one at a time. To
implement a Bluespec program in hardware, the compiler needs to
generate a deterministic schedule where one or more rules happen each
clock-cycle. 
%
It was argued that scheduling can be implemented as rule
composition~\cite{DBLP:conf/memocode/DaveAP07}, using a few
combinators. 
%
In Fe-si, we look forward to implement more combinators that make it
possible to assemble more efficient circuits, in a sound and precise
way.
%

\subsubsection{Non-determinism}
Non-determinism is useful when it comes to specification; and we find
it pleasant to have a deterministic semantics for our Fe-Si
programs. We would argue to have non-deterministic

\section{Implementation}
The compiler implementation and documentation are available on- line
at: 
%
\begin{center}
  \texttt{htt://foo.bar}
\end{center}




\bibliography{synthesis}

\end{document}

% \begin{figure}
%   \centering
%   \begin{twolistings}
    
%   \begin{ocaml}
% type tree =
% | L of int
% | N of tree * tree

% let cmp x y = min x y, max x y

% let rec min_max_swap l r =
% match l,r with 
% | L x, L y -> let (a,b) = cmp x y in 
%   L a, L b
% | N (l1,r1), N (l2,r2) -> 
%   let (a,b) = min_max_swap l1 l2 in 
%   let (c,d) = min_max_swap r1 r2 in 
%   (N (a,c), N (b,d))
% \end{ocaml}
% &$\quad$
% \begin{ocaml}
% let rec reverse = function 
% | L x -> L x
% | N (l,r) -> N (reverse r, reverse l)

% let rec merge = function
% | L x -> L x
% | N (l,r) -> let (a,b) = min_max_swap  l r in
%   N (merge a, merge b)

% let rec sort = function
% | L x -> L x
% | N (l,r) -> merge (N (sort l, reverse (sort r)))

% $ $
% \end{ocaml}
% \end{twolistings}
% \caption{Bitonic sort in OCaml}
% \label{fig:bitonic-ocaml}
% \end{figure}
